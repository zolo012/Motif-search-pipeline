import pickle
import pandas
import requests
from Final_motif_search import *

# A. Retrieve PPI data
intact_data_dir = '/home/zolo012/KELCH/KLHL12_PPI/Intact_db/'
biogrid_data_dir = '/home/zolo012/KELCH/KLHL12_PPI/Biogrid_db/'
integrated_data_dir = '/home/zolo012/KELCH/Motif_search_v1/Protein_results/Integrated_data/'
human_proteom_place = '/home/zolo012/Human_proteom/human_proteom_no_isoforms_dictionary'

# Open human proteom
infile = open(human_proteom_place, 'rb')
human_proteom_dicty = pickle.load(infile)

header_names_list = ['protein id', 'gene id', 'start', 'motif', 'iupred', 'pfam', 'phobius', 'uniprot subcellular location', 'uniprot topology', 'topology decision', 'slimprint', 'slimprint score', 'slimprint decision',
                     'evolutionary level', 'removed sequences fraction', 'shannon', 'regex score', 'regex fraction', 'evolutionary level.1', 'removed sequences fraction.1', 'shannon.1', 'regex score.1', 'regex fraction.1', 'evolutionary level.2', 'removed sequences fraction.2', 'shannon.2', 'regex score.2', 'regex fraction.2', 'evolutionary level.3', 'removed sequences fraction.3', 'shannon.3', 'regex score.3', 'regex fraction.3', 'evolutionary level.4', 'removed sequences fraction.4', 'shannon.4', 'regex score.4', 'regex fraction.4', 'evolutionary level.5', 'removed sequences fraction.5', 'shannon.5', 'regex score.5', 'regex fraction.5', 'final decision', 'ppi methods', 'ppi scores']

# 1. Intact database
# Download PPI data from Intact database otherwise if just download manually from website no MI score in them
retrieve_data_intact({'KLHL12' : ['Q53G59']}, intact_data_dir)

# Create intact data dictionary: {interacting_protein_id : {detection_method : [MI_score, MI_score]}}
#intact_data_dicty = intact_ppi_dicty_create(intact_data_dir + 'Q53G59', 'Q53G59')

# Save intact_data_dicty

outfile = open('/home/zolo012/KELCH/KLHL12_PPI/Intact_db/intact_data_dicty', 'wb')
pickle.dump(intact_data_dicty, outfile)
outfile.close()

# Load intact_data_dicty
infile = open('/home/zolo012/KELCH/KLHL12_PPI/Intact_db/intact_data_dicty', 'rb')
intact_data_dicty = pickle.load(infile)
infile.close()

# 2. BIOGRID data

# Open PPI data from Biogrid which was only downloaded by hand from website (https://thebiogrid.org/) and create a dictionary based on that: {interacting_protein_id : {method : occurrence}}}
biogrid_data_dicty = biogrid_ppi_dicty_generate(biogrid_data_dir + 'BIOGRID-GENE-121890-4.4.207.mitab.txt', 'Q53G59')

# Save biogrid_data_dicty
outfile = open('/home/zolo012/KELCH/KLHL12_PPI/Biogrid_db/biogrid_data_dicty', 'wb')
pickle.dump(intact_data_dicty, outfile)
outfile.close()

# Load biogrid_data_dicty
infile = open('/home/zolo012/KELCH/KLHL12_PPI/Biogrid_db/biogrid_data_dicty', 'rb')
biogrid_data_dicty = pickle.load(infile)
infile.close()

# Create a dictionary that contains all integrated data of all motif containing proteins
protein_dicty = integrate_data_dicty_generate(integrated_data_dir)


# Use retrieved PPI data and add method and PPI those proteins that contain any putative KELCH motif(s)
intact_biogrid_ppi_add(protein_dicty, human_proteom_dicty, intact_data_dicty, biogrid_data_dicty, '/home/zolo012/KELCH/Motif_search_v1/Result/motif_search_all_090_shannon', header_names_list)


# High confidence list generation: have either PPI or accepted slimprint or both
# input: dictionary generated by intact_biogrid_ppi_add
# output dictionary: {protein_id : {start : [motif, Iupred_score, Iupred_decision, pfam, pfam_decision, ]} }
def high_conf_list_generate(motif_dicty):
    # loop through accepted motifs
    cntr = 0
    res_dicty = {}
    for protein_id in motif_dicty:
        for start in motif_dicty[protein_id]:
            if motif_dicty[protein_id][start][40] == 'ACCEPTED' and (motif_dicty[protein_id][start][9] == 'ACCEPTED' or motif_dicty[protein_id][start][41] != '-'):
                print(protein_id, start)
                if protein_id not in res_dicty.keys():
                    res_dicty.update({protein_id: {}})
                res_dicty[protein_id].update({start : copy.deepcopy(motif_dicty[protein_id][start])})
                cntr += 1
    res_cntr = 0
    for protein_id in res_dicty:
        for start in res_dicty[protein_id]:
            res_cntr += 1
    print(res_dicty)
    print(cntr)
    print(res_cntr)
    return  res_dicty

high_conf_dicty = high_conf_list_generate(motif_search_dicty)

# Create output_file
final_motif_search_res_file_create(high_conf_dicty, human_proteom_dicty, header_names_list, high_confidence_file_path)

# Count number of surviving proteins, motifs and motif types + save those that are accepted and have either slimprint score or
protein_set, motif_set, motif_list = set(), set(), list()
good_slimprint_set, good_ppi_set = set(), set()
# loop through protien 
for protein in protein_dicty:
    print(protein)
    for start in protein_dicty[protein]:
        print(protein_dicty[protein][start][40])
        if protein_dicty[protein][start][40] == 'ACCEPTED':
            print(protein_dicty[protein][start][9], protein_dicty[protein][start][41])
            motif = protein_dicty[protein][start][0]
            protein_set.add(protein)
            motif_set.add(motif)
            motif_list.append(motif)
            # 1, extract good slimprint containing motifs
            if protein_dicty[protein][start][9] == 'ACCEPTED':
                good_slimprint_set.add(protein + ' ' + start)
            # 2, extract ppi data containing motifs
            if protein_dicty[protein][start][41] != '-':
                good_ppi_set.add(protein + ' ' + start)

print('Number of survived proteins: {}\nNumber of survived motif types: {}\nNumber of survived motifs: {}'.format(len(protein_set), len(motif_set), len(motif_list)))
print('Number of survived proteins having PPI and Slimprints: {}\nNumber of survived proteins having only PPI: {}\nNumber of survived proteins having only Slimprint: {}'.format(len(good_slimprint_set.intersection(good_ppi_set)), len(good_ppi_set.difference(good_slimprint_set)), len(good_slimprint_set.difference(good_ppi_set))))

print(good_slimprint_set)
print(good_ppi_set)


# Save them
infile = open('/home/zolo012/KELCH/Motif_search_v1/Result/good_slimprint_set', 'wb')
pickle.dump(good_slimprint_set, infile)
infile.close()

infile = open('/home/zolo012/KELCH/Motif_search_v1/Result/good_ppi_set', 'wb')
pickle.dump(good_ppi_set, infile)
infile.close()

print(protein_dicty[protein][start])


